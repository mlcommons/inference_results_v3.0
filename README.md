# MLPerf™ Inference v3.0 results
This repository contains the results and code for the MLPerf™ Inference v3.0 benchmark.

For benchmark code and rules please see the [main MLPerf Inference repository](https://github.com/mlcommons/inference).

Additionally, each organization has written approximately 300 words to help explain their submissions in the [Supplemental discussion](https://github.com/mlcommons/inference_results_v3.0/blob/main/MLPerf%E2%84%A2%20Inference%20v3.0.%20Supplemental%20Discussion.pdf).

## Archive Notice
This repository of results from a prior MLPerf Inference round has been archived. Please raise an issue in the [main MLPerf Inference repository](https://github.com/mlcommons/inference) or contact the MLPerf Inference chairs (inference-chairs@mlcommons.org) if you would like to make a change to this results repo.
