For the mobilenet and efficientnet models we are using the [TFLite cpp implementation](https://github.com/mlcommons/ck/tree/master/cm-mlops/script/app-mlperf-inference-tflite-cpp) where tensorflow lite is built from the source. For this submission we used TFLite with XNNPACK enabled and also TFLite using ArmNN library. Please follow [this README](https://github.com/mlcommons/ck/blob/master/cm-mlops/script/run-mlperf-inference-mobilenet-models/README-about.md) to produce and end to end submission for mobilenet and efficientnet models using tflite.
